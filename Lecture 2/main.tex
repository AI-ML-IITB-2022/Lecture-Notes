\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{scribe}
\usepackage{listings}

\Scribe{Group 1 and Group 2}
\Lecturer{Abir De}
\LectureNumber{1}
\LectureDate{8 August 2022}
\LectureTitle{Probability Theory}

\lstset{style=mystyle}

\begin{document}
	\MakeScribeTop

%#############################################################
%#############################################################
%#############################################################
%#############################################################

% This is some warmup discussion before the first section.

% \section{Here's a section header}

% Here's some more text.
% % Here's a citation~\cite{Kar84a}.

% \subsection{Here's a subsection}

% You might like to put use subsectioning these too.  An alternate way to put in a small subheading for a paragraph is to use the \begin{verbatim} \paragraph \end{verbatim} command.  For example:

% \paragraph{A remembrance by Dantzig.}  The early days were full of intense excitement. Scientists, free at last from war-time pressures, entered the post-war period hungry for new areas of research. The computer came on the scene at just the right time. Economists and mathematicians were intrigued with the possibility that the fundamental problem of optimal allocation of scarce resources could be numerically solved. Not too long after my first meeting with Tucker there was a meeting of the Econometric Society in Wisconsin attended by well-known statisticians and mathematicians like Hotelling and von Neumann, and economists like Koopmans. I was a young unknown and I remember how frightened I was at the idea of presenting for the first time to such a distinguished audience, the concept of linear programming.



% \section{Math stuff}

% Please make an effort to typeset things nicely.  There are quite a few macros in the lpsdp.sty file.  Below are illustrated how to do some basic things; please study the \LaTeX\ carefully.

% Here's a typical LP in standard/equational form, with an equation number on one of the constraints.
% \begin{gather}
%     \min \quad c^\top x                       \nonumber\\
%     \begin{aligned}
%         \text{s.t.} \quad   Ax &= b           \nonumber\\
%                              x &\geq 0       \label{eqn:nonnegative}
%     \end{aligned}
% \end{gather}

% \noindent Here's a reference to the~\eqref{eqn:nonnegative} nonnegativity constraint.  Some more LPs:

% \begin{gather*}
%     \min \quad 3x_1 - 5x_2 \\
%     \begin{aligned}
%         \text{s.t.} \quad   x_1 + 2x_2 &\leq 6\\
%                             2x_1 + x_2 &\leq 6\\
%                             2x_1 + 2x_2 &\geq 7\\
%                             x_1,x_2 &\geq 0
%     \end{aligned}
% \end{gather*}

% \begin{alignat*}{3}
%     \text{minimize}&   \quad & 3x_1 - 5x_2 + 2x_3 - x_4&       & &\\
%     \text{subject to}& \quad & x_1 + 2x_2 - 4x_3 + x_4 &\leq 6 & &\\
%                            & & -x_1 + 3x_2 - x_3 - x_4 &\geq 7 & &\\
%                            & & x_i &\geq 0  & &\quad \forall i = 1\dots 4
% \end{alignat*}

% \begin{align}
%     & \min_{\varepsilon^{up}, \varepsilon^{dw}, \beta}  &&  \sum_{i \in Observations} {\varepsilon^{up}}_i + {\varepsilon^{dw}}_i  && \notag \\
%     & \text{subject to}     &&  {\varepsilon^{up}}_i \geq + y_i - \sum_{j \in Candidates} \beta_j x_{i,j} && \forall i \in Observations \notag \\
%     &                       &&  {\varepsilon^{dw}}_i \geq - y_i + \sum_{j \in Candidates} \beta_j x_{i,j} && \forall i \in Observations \notag \\
%     &                       &&  {\varepsilon^{up}}_i, {\varepsilon^{dw}}_i \geq 0 && \forall i \in Observations \notag \\
% \end{align}

% \begin{alignat*}{4}
% z_k(x) \ = \ & \min_{y_k}        &       &  f_k^T y_k &&                  \notag \\
%              & \text{subject to} & \quad &  D_k y_k   &&  = d_k - B_k x  \notag \\
%              &                   &       &  y_k       && \geq 0          \notag \\
% \end{alignat*}

% Huge LP's:

% \begin{align}
%     & \min_{x, y_k}     &&  c^T x && + f_1^T y_1 && + \dots && + f_n^T y_n  &&  \notag \\
%     & \text{subject to} &&  Ax    &&             &&         &&              && = b \notag \\
%     &                   &&  B_1 x && + D_1 y_1   &&         &&              && = d_1 \notag \\
%     &                   &&  \dots &&             &&  \dots  &&              &&       \notag \\
%     &                   &&  B_n x &&             &&         && + D_n y_n    && = d_n \notag \\
%     &                   &&   x,   &&     y_1,    &&         &&       y_n    && \geq 0 \notag \\
% \end{align}


% Let's do some matrices:
% \[
% \begin{pmatrix}
%     1 & \rho & \rho\\
%     \rho & 1 & \rho\\
%     \rho & \rho & 1\\
% \end{pmatrix},
% \quad \text{or alternately,} \quad
% \begin{bmatrix}
%     1 & 2 \\
%     3 & 4 \\
% \end{bmatrix}.
% \]
% More generically:
% \[
%     A = \begin{bmatrix}
%             \vrule & \vrule & & \vrule\\
%             A_{1} & A_{2} & \cdots & A_{n} \\
%             \vrule & \vrule & & \vrule
%         \end{bmatrix}
%       = \begin{bmatrix}
%             \text{---} & a_1 & \text{---} \\
%             \text{---} & a_1 & \text{---} \\
%                        & \vdots &  \\
%             \text{---} & a_n & \text{---} 
%         \end{bmatrix}
% \]


% Here's some more random typesetting: 
% \begin{itemize}
% \item ``PTIME vs. NP, where the former means time $\poly(n)$'';
% \item $\wt{O}(f(x)) \text{ is } f(x) \cdot \polylog(f(x))$;
% \item $\displaystyle 
%         g(x) = \begin{cases}
%                    \sin(2\theta) & \text{if $\theta \leq \pi$,}\\
%                    \max\{\cos^2\theta, \tfrac13\} & \text{if $\theta > \pi$.}
%                \end{cases}
%       $
% \end{itemize}
% Please don't write $max(A)$ when you mean $\max(A)$, or $log(n)$ when you mean $\log(n)$, or "quotes" when you mean ``quotes''.

% \

% More equations:

% $\max \Big\{ \sum_{i \in Observations} \Big( y_i - \sum_{j \in Candidates} \beta_j x_{i,j} \Big) ^2 \Big\}$

% $\max\Bigg\{ \sum_{i \in Observations} \Big| y_i - \sum_{j \in Candidates} \beta_j x_{i,j} \Big| \Bigg\}$

% A theorem and a proof:
% \begin{theorem} $(a+b)^2 = a^2 + 2ab + b^2$.
% \end{theorem}
% \begin{proof}
% Let for the reader.
% \end{proof}

% \bigskip

% Here's what to do if your proof ends on an equation:
% \begin{proof}
% It's easy:
% \[
%     (a+b)^2 = (a+b)(a+b) = (a+b)a + (a+b)b = a^2 + ba + ab + b^2 = a^2 + 2ab + b^2 \qedhere
% \]
% \end{proof}

% And a lemma without proof:
% \begin{lemma}
% Suppose numbers exist, then $(a+b)^2 = a^2 + 2ab + b^2$.
% \end{lemma}

% You can do a few others:
% \begin{example}
% Suppose numbers exist, then $(a+b)^2 = a^2 + 2ab + b^2$.
% \end{example}
% \begin{conjecture}
% Suppose numbers exist, then $(a+b)^2 = a^2 + 2ab + b^2$.
% \end{conjecture}
% \begin{definition}
% Suppose numbers exist, then $(a+b)^2 = a^2 + 2ab + b^2$.
% \end{definition}
% \begin{observation}
% Suppose numbers exist, then $(a+b)^2 = a^2 + 2ab + b^2$.
% \end{observation}
% \begin{remark}
% Suppose numbers exist, then $(a+b)^2 = a^2 + 2ab + b^2$.
% \end{remark}
% \begin{claim}
% Suppose numbers exist, then $(a+b)^2 = a^2 + 2ab + b^2$.
% \end{claim}



% Please insert figures liberally.  It's probably best if ``vector graphics'' are in pdf or png format, and ``bitmap graphics'' are in jpg format, but lots formats are supported.  There's a macro defined to make things easy.  Inkscape is a pretty reasonable, free program in which to draw figures.
 
% %%%%%%%% FIGURES
% % first parameter is a real number which is the scale factor; 
% % second is the file name; 
% % third is caption; 
% % fourth gives the LaTeX label for future \ref
% \myfig{.375}{example-figure.pdf}{The region $g_1 > 0, g_2 > -\tfrac{\rho}{\sqrt{1-\rho^2}}g_1$.}{fig:my-example}

% Once you've inserted it, you can refer to it as Figure~\ref{fig:my-example}.\\

% Here there is an example of some code
% \begin{lstlisting}[language=Julia]
% using JuMP, GLPK

% function production_model()
%     # Define an optimization model
%     m = Model(with_optimizer(GLPK.Optimizer))
    
%     # Variables
%     @variable(m, x[i in 1:2] >= 0)
    
%     # Constraints
%     @constraint(m, 2*x[1] + x[2] <= 4)
%     @constraint(m, x[1] + 2*x[2] <= 4)
    
%     # Objective function
%     @objective(m, Max, 4*x[1] + 3*x[3])
    
%     # Solve the model
%     optimize!(m)
    
%     return objective_value(m)
% end
% \end{lstlisting}
% Finally, if you have citations, see the commented-out stuff in the \LaTeX~here.

% \

% My farourive Optimization books are \cite{bertsimas1997introduction} \cite{boyd2004convex} \cite{wolsey2014integer}. You should add bibliographical notes in the \textbf{BibTex}: \textit{mybib.bib} file. Its good to grab these notes from Google scholar citations.

% %%%%%%%%%%% If you don't have citations then comment the lines below:
% %
% \bibliographystyle{abbrv}           % if you need a bibliography
% \bibliography{mybib}                % assuming yours is named mybib.bib

In the first lecture of the course, we began with a review of the basics of probability theory and some discussions on ``what is ML?''. We discussed how ML is used to recognize patterns in data, without explicitly being told which patterns there are.

We recalled the characteristics of Supervised Learning and Unsupervised Learning, which differ in whether the training data available is labelled or not. We then began with the review of probability theory.

\section{Probability}

% Here's a citation~\cite{Kar84a}.


\subsection{Review}
\begin{itemize}
    \item \textbf{Sample Space (S)} : In probability theory, the sample space of an experiment or random trial is defined as the set of all possible outcomes of that experiment.
    \begin{gather*}
        P(S)=1 ,\hspace{2pt} P(\emptyset)=0
    \end{gather*}
% \end{itemize}

% \begin{itemize}

    \item \textbf{Probability Distribution ($p$)} : Probability Distribution is a Mathematical function which outputs the probabilities of occurrence of different possible outcomes of an experiment.
    \begin{gather*}
        p:S\xrightarrow[]{}[0,1]  \\
        s.t.  \sum_{x\in S} p(x) = 1 
    \end{gather*}
    
    \item \textbf{Random Variable (X)}: A random variable can be defined as a numerical description of the outcome of a statistical random experiment. It is a mapping from the set of outcomes in the sample space to numbers.
% \end{itemize}

% \begin{itemize}
    \item \textbf{Event(E)} :
    Events can be defined as the set of outcomes of an experiment. An event can be just one outcome or it can be a combination of more than one outcome from an experiment. 
    It can be defined as a subset of the experiment's sample space.
    \begin{gather*}
        E\subseteq S
    \end{gather*}
    For example, in the dice roll experiment, the sample space is S = \{1,2,3,4,5,6\} ; one possible outcome is "1"; while a possible event is "The dice rolled an odd number", E = \{1,3,5\}. \\
    We often describe the events using conditions and these events can be combined using logical operations like \textbf{or},\textbf{and}.
% \end{itemize}

% \begin{itemize}
    \item \textbf{Probability of an Event} : It tells us the likelihood of happening of the event. Mathematically it is the total weight assigned to all the elements in the
    event by a given probability distribution.
    \begin{gather*}
        P(E) = \sum_{x\in S} p(x) \\
        P(\overline{E}) = 1-P(E) , \hspace{2pt} \overline{E} = S \setminus  E\\
        P(E_{1}\cup E_{2}) = P(E_{1}) + P(E_{2}) - P(E_{1}\cap E_{2})
    \end{gather*}
    
    \begin{itemize}
        \item \textbf{Union bound :} This is an inequality used extensively in probability theory. It states that the probability of union of some events is less than or equal to the sum of probabilities of each individual event.
        \begin{gather*}
            P(E_{1}\cup E_{2}) \leq P(E_{1}) + P(E_{2})
        \end{gather*}
    % \end{itemize}
    
    
        \item If E$_{1}$, E$_{2}$, $\ldots$, E$_{n}$ are pairwise disjoint events, then
        \begin{gather*}
            P(\bigcup_{i=1}^{n} E_{i}) = \sum_{i=1}^{n} P(E_i)
        \end{gather*}
        
        \item \textbf{Conditional Probability} It is the probability of an event happening given that another event has already occurred. For events E$_{1}$ and E$_{2}$ (s.t P(E$_{2}$)>0)
        \begin{gather*}
            P(E_{1}|E_{2}) = \frac{P(E_{1}\cap E_{2})}{P(E_{2})}
        \end{gather*}
        
        \item \textbf{Bayes' Rule} This Rule can be derived from the definition of conditional probability. It is named after Thomas Bayes(1701-1761). For events A and B (s.t P(A),P(B)>0)
        \begin{gather*}
            P(A|B) = \frac{P(B|A)P(A)}{P(B)}
        \end{gather*}
    \end{itemize}
\end{itemize}

\subsection{Applications of probability}\subsubsection{Probability in Medical Testing}
A lab test has a probability 0.95 of detecting a disease when applied to a person suffering from said disease, and a probability 0.10 of giving a false positive when applied to a non-sufferer. If 0.5\% of the population are sufferers, what is the probability of a test being positive?\\ \\
\textbf{Solution:}
Let \\ \\
\textbf{Pos} be the event that result of the test is Positive\\ \textbf{Neg} be the event that result of the test is Negative\\
\textbf{S} be the event that person is a sufferer \\ 
\textbf{NS} be the event that person is not a sufferer. \\ \\
Given that
\begin{gather*}
    P(Pos|S) = 0.95\\
    P(Pos|NS) = 0.10\\
    P(S) = 0.005
\end{gather*}
we need to find probability of a test being positive i.e $P(Pos)$
\begin{gather*}
    P(Pos) = P(Pos\cap S) + P(Pos\cap NS)\\
    P(Pos) = P(Pos|S)*P(S) + P(Pos|NS)*P(NS)\\
    P(Pos) = 0.95*0.005 + 0.10*0.995\\
    P(Pos) = 0.10425
\end{gather*}

0.10425 is the probability of a test being positive

\subsubsection{Probability in NLP}
Part Of Speech (POS) tagging is a popular Natural Language Processing (NLP) Problem.\\
Here Input is a set of N words and the output is POS tag for each word.

Assuming each word is independently drawn from a fixed vocabulary, find the probability that a sentence of length m contains a 'noun' given that it contains a 'verb'.\\ \\
\textbf{Solution:}
Let p$_{k}$ be the probability that a word is of POS type 'k' and let A$_{k}$ be the event that sentence contains POS type 'k'.

we need to find $P(A_{noun}|A_{verb})$. we already know that
\begin{gather*}
    P(A_{noun}|A_{verb}) = \frac{P(A_{noun}\cap A_{verb})}{P(A_{verb})}\\
    P(A_{noun}\cap A_{verb}) = 1 - P(\overline{A_{noun}\cap A_{verb}})\\
    P(A_{noun}\cap A_{verb}) = 1 - P(\overline{A_{noun}}\cup \overline{A_{verb}})\\
    P(A_{noun}\cap A_{verb}) = 1 - (P(\overline{A_{noun}}) + P(\overline{A_{verb}}) - P(\overline{A_{noun}}\cap \overline{A_{verb}}))\\
    P(A_{noun}\cap A_{verb}) = 1 - P(\overline{A_{noun}}) - P(\overline{A_{verb}}) + P(\overline{A_{noun}}\cap \overline{A_{verb}})
\end{gather*}

we now represent $P(A_{k})$ in terms of $p_{k}$ and length of the sentence i.e m by subtracting the probability from 1 that no POS type 'k' word is present in the sentence.

\begin{gather*}
    P(\overline{A_{k}}) = (1-p_{k})^m\\
    P(A_{k}) = 1 - (1-p_{k})^m
\end{gather*}

$P(\overline{A_{noun}}\cap \overline{A_{verb}})$ is nothing but the probability of both A$_{noun}$ and A$_{verb}$ events not happening
\begin{gather*}
    P(\overline{A_{noun}}\cap \overline{A_{verb}}) = (1-(p_{noun}+p_{verb}))^m
\end{gather*}

Now we use this to calculate the required answer

\begin{gather*}
    P(A_{noun}\cap A_{verb}) = 1 - (1-p_{noun})^m - (1-p_{verb})^m + (1-(p_{noun}+p_{verb}))^m\\
    P(A_{verb}) = 1 - (1-p_{verb})^m
\end{gather*}
\textbf{Final Answer:}
\begin{gather*}
    P(A_{noun}|A_{verb}) = \frac{1 - (1-p_{noun})^m - (1-p_{verb})^m + (1-(p_{noun}+p_{verb}))^m}{1 - (1-p_{verb})^m}
\end{gather*}

\section{Marginals and Independence}

\begin{itemize}
\item {Joint Distribution}: 
It can be simply defined as the probability of two events (corresponding to two random variables) happening together. It can be extended to $>$ 2 RVs.
\begin{align*} 
    p_{XY}(x,y)=P(X=x\hspace{0.2cm}and \hspace{0.2cm}Y=y)
\end{align*}

\item Marginal Distribution:  Probability distribution of the variables contained in the subset of a collection of random variables. 
\begin{align*}
    Pr(X=x)=\sum _{y \in S_2}Pr((X,Y)=(x,y)), x \in S_1
\end{align*}
\item Independent Random Variable
\begin{align*}
X \amalg Y \Leftrightarrow P(X=x,Y=y)=P(X=x)P(Y=y)\hspace{0.5cm} \forall x,y
\end{align*}

In terms of conditional probability: \hspace{2pt}
$P(X|Y) = P(X)$

\item Conditionally Independent Random Variable \\
\textit{X and Y are conditionally independent given Z :}
\begin{align*}
p(x,y|z)=p(x|z)p(y|z) \hspace{0.5cm} \forall x,y,z \hspace{0.5cm}(p(z) > 0)
\end{align*}

\end{itemize}


\par In machine learning, if given a pair of dependent random variables, we often try to find a random variable $Z$, so that they become independent conditional to $Z$.

\section{Expectation}
For a random variable $X$ on $\mathbb{R}$, with a probability mass function $P$, the expectation is defined as $\E[X]=\sum_{x} P(X=x)$. Expectation has the following properties:
\begin{itemize}
    \item \textbf{Linearity} : $\E[X+Y] = \E[X] + \E[Y]$
    \item \textbf{Linearity} : $\E[cX] = c\E[X]$
    \item \textbf{Expectation as the minimizer of squared error} : We try to find $z$ such that $\E[(X-z)^2]$ is minimized. Equating the derivative of this with respect to $z$ to $0$, we get $z=\E[X]$
    \item \textbf{Expecation of product of independent random variables} : $\E[XY]=\E[X]\E[Y]$. This can be shown as:
        \begin{equation*}
            \E[XY] = \sum_{x,y} P(X=x, Y=y)xy = \sum_x P(X=x)x \sum_y P(Y=y)y = \E[X]\E[Y]
        \end{equation*}
\end{itemize}

Refer to the Appendix for proof of these properties.

\section{Variance}
Variance of a random variable is a measure of the deviation of the random variable from it's mean. The \textbf{variance} of a random variable X with E[X] = µ is defined as:
    \begin{gather} 
        \begin{aligned}
         \quad   Var [X] = E [(X − µ)^2] = E [X^2 ] − µ^2
               \label{eqn:nonnegatie}
        \end{aligned}
    \end{gather}
     \textbf{Properties:}
    \begin{itemize}
        \item $Var [X + \beta ] = Var [X ]$
        \item $Var [\alpha X ] = \alpha^2 Var [X ]$
        \item If $X_1,\ldots,X_n$ are pairwise independent, then $Var[\sum_i X_i] = \sum_i Var[X_i]$
         \item If $X_1,\ldots,X_n$ are pairwise independent, each with variance $\sigma^2$, then $Var[\sum_i X_i / n] = \frac{\sigma^2}{n}$
    \end{itemize}
    
Refer to the Appendix for proof of these properties.

    \subsection{Chebyshev's Inequality}
    If X is a random variable with mean $\mu$ and variance $\sigma^2$, then $\forall \alpha$ > 0
    \begin{gather} 
        \begin{aligned}
         \quad Pr[|X − \mu| ≥ \alpha] ≤ \frac{\sigma^2}{\alpha^2}
               \label{eqn:nonnegatie}
        \end{aligned}
    \end{gather}

\subsection{Covariance}
    It is a measure of \textbf{joint variability} of two random variables. For random variables $X$ and $Y$, \textbf{covariance} is defined as:
    \begin{gather} 
        \begin{aligned}
         \quad   Cov [X , Y ] = E [(X − E (X ))(Y − E (Y ))] = E [XY ] − E [X ]E [Y ]
               \label{eqn:nonnegatie}
        \end{aligned}
    \end{gather}
     \textbf{Properties:}
    \begin{itemize}
        \item $Cov [X , X ] = Var [X ]$
        \item $Cov [X + Z , Y ] = Cov [X , Y ] + Cov [Z , Y ]$
        \item $Cov [ \sum_i{X_i} , Y ] = \sum_i Cov [X_i , Y ]$
        \item $Cov[X, Y] = 0$ , if $X$ and $Y$ are independent
    \end{itemize}

\section{Sum of random variables}
Consider two independent random variables $X, Y$. Then, their sum $Z = X+Y$ is a random variable with a probabilities mass function as the convolution of the probability mass functions of $X$ and $Y$.
\begin{equation*}
    P(Z=z) = \sum_{x}P(X=x) P(Y=z-x)
\end{equation*}
    
\section{Some Important Distributions}


% Here's a citation~\cite{Kar84a}.

    
\textbf{Notation}: $X ∼ D$ if the random variable X takes its values according to
some distribution $D : S → [0, 1]$.
\\ \\
\textbf{Bernoulli Random Variable}\\ Takes values from $S = {0, 1}$.
A single \textbf{parameter} $q \in [0, 1]$ fully 
specifies a Bernoulli random variable, where
$Pr[X = 1] = q$ (and $Pr [X = 0] = 1 − q$). \\
It is denoted by $Bern(q)$.\\ \\
If $X ∼ Bern(q)$ then
\begin{itemize}
 \item$E [X ] = (1 − q) × 0 + q × 1 = q$
 \item$Var [X ] = q − q^2 = q(1 − q)$
\end{itemize}
\textbf{Binomial Random Variable}\\
A \textbf{binomial random variable} models how often a particular outcome occurs in a fixed number of trials of an experiment whose outcome can be modeled as a Bernoulli random variable.\\
It is denoted by $B(n, q)$. \\ \\
Formally, if $Y = \sum_{i=1}^n{X_i}$ , where $X_i ∼ Bern(q)$ are i.i.d., then $Y ∼ B(n, q)$.
If $Y ∼ B(n, q)$ then
\begin{itemize}
\item $P(Y=k)=\binom{n}{k}q^k(1-q)^{n-k}$
    \item $E [Y ] = nq $
    \item $Var [Y ] = nq(1 − q)$
\end{itemize}
\section{Continuous distributions}
A continous random variable can be defined as a random variable which can take an infinite number of values across a range.

For a continuous random variables $X$, on a domain $S$, we define \begin{itemize}
    \item \emph{Probability Distribution Function}(PDF) as a function $f:S \to \mathbb{R}_0^+$ with the probability of X taking a value inside $D \subseteq S$ being $\int_D f(x)dx$.
    \item  \emph{Cumulative Distribution Function}(CDF) as a function $F : \mathbb{R} \to [0,1]$
\begin{align*}
    F(x) &= P(X \le x)\\
        &= \int_{-\infty}^{x} f(x)dx
\end{align*}
\end{itemize}



\textbf{Note} The key difference between continous and discreet distributions lies in the the concepts of mass and density. \\ \\
When the sample space S of random variable is:
\begin{itemize}
\item Discrete: The distribution assigns weights/probabilities to individual points
\item Continuous: The distribution assigns density to all points such that the integral over the whole range is 1
\end{itemize}

\subsection{Joint distribution}
For two random variables $X, Y$ on $\mathbb{R}$, the joint distribution is a function $f : \mathbb{R}^2 \to \mathbb{R}_0^+$, defined such that for all $D \subseteq \mathbb{R}^2$, we have
\begin{align*}
    P((X, Y) \in D) &= \int_D f((x, y)) dxdy
\end{align*}
\paragraph{Marginals} For a joint distribution $f$, the marginals $f_x$ and $f_y$ are the probabilities of the variables $X$ and $Y$ taking some particular value. Hence, $f_x(t) = \int_{-\infty}^{\infty} f(t, y) dy$ and $f_y(t) = \int_{-\infty}^{\infty} f(x, t) dt$. This integral is often difficult to compute in practice, so we make use of the following trick:
\begin{align*}
    f_x(t) &= \int_{-\infty}^{\infty} P(X = t|Y = y) f_y(y)dy\\
         &=  \E_{y \sim f_y}[P(X=t | Y=y)]
\end{align*}
This can be evaluated easily using the law of large numbers if it is easy to sample from the distribution $f_y$
\paragraph{Independence} The variables $X$ and $Y$ are said to be independent if their joint distribution can be decomposed into the product of their PDFs i.e. $f(X,Y) = f_x(X) f_y(Y)$.
\paragraph{Conditionals} The conditional density $f_x(x | Y = y)$, is the probability density of $X$, given that $Y$ takes the value $y$. It is equal to $\frac{f(x,y)}{f_y(y)}$


\section{Recovering the PDF from data}
Consider a PDF $f : \mathbb{R} \to \mathbb{R}^+_0$ for a random variable $X$, which is unknown to us. We have a generator which allows us to generate i.i.d. samples from this PDF countably many times. We have the task of estimating what the PDF is, given the i.i.d. samples $\{x_1,x_2, x_3, \cdots x_n\}$.

We will first find the moments of the distribution using the Law of Large Numbers.
\begin{align*}
    \E_f[X^k] &= \lim_{n \to \infty} \frac{x_1^k + x_2^k +  \cdots + x_n^k}{n}
\end{align*}
Now, we find the moment generating function $M(\omega)$ of the distribution.
\begin{align*}
    M(\omega) &= \int_{-\infty}^{\infty} e^{\iota \omega x} f(x) dx\\
              &= \int_{-\infty}^{\infty} \left( 1 + \iota \omega x - \frac{\omega^2 x^2}{2!} - \iota \frac{\omega^3 x^3}{3!} \cdots \right) f(x)dx\\
              &= 1 + \iota \omega \E[X] - \frac{\omega^2 \E[X^2]}{2!} - \iota \frac{\omega^3 \E[X^3]}{3!} \cdots
\end{align*}
Once we have evaluated the moment generating function, we use the Inverse Fourier Transform to recover the PDF.
\begin{align*}
    f(x) &= \frac{1}{2\pi}\int_{-\infty}^{\infty} e^{-\iota \omega x} M(\omega) d\omega
\end{align*}


\section{Appendix}
\label{Appendix}

\subsection{Properties of Expectation}
\begin{enumerate}
    \item $E[X+Y] = E[X]+E[Y]$
    \vspace{-10pt}
    \begin{proof}
        Let S is the sample space
        \begin{align*}
            E[X+Y] &= \Sigma_{s \in S}(X(s)+Y(s)) P(s)\\
                    &= \Sigma(s \in S) X(s) P(s) +\Sigma_{s \in S}Y(s) P(s)\\
                    &= E[X] +E[Y]
        \end{align*}
    \end{proof}
    \item $E[(X-c)^2] \geq E[(X-\mu)^2]$ where, $\mu = E[X]$ for any constant $c$ and random variable $X$
     \vspace{-10pt}
    \begin{proof}
    By linearity of expectation, we have,
    \begin{align*}
        E[(X-a)^2] &= E[X^2+a^2-2aX]\\
                    &= E[X^2] +a^2- 2aE[X]\\
                    &= (E[X]-a)^2 +E[X^2]-E[X]^2\\
    \end{align*}
    As we will see later that, $Var(X) = E[X^2]-E[X]^2 =E[(X-\mu)^2]$, where $\mu=E[X]$ therefore,
    \[E[(X-a)^2] \geq E[(X-\mu)^2]\]
    
        
    \end{proof}
    
    \item $E[cX] = cE[X]$ for any constant $c$ and random variable $X$.
     \vspace{-10pt}
    \begin{proof}
        \begin{align*}
            E[cX] &= \Sigma_{s \in S} cX(s) P(s)\\
                  &= c \Sigma_{s \in S} X(s) P(s) \\
                  &= c E[X]
        \end{align*}
    \end{proof}
    
    \item $E[XY] = E[X]E[Y]$, If $X$ and $Y$ are independent
     \vspace{-10pt}
    \begin{proof}
        \begin{align*}
            E[XY] &= \Sigma_{x,y} xy P(X=x) P(Y=y)\\
                    &= \Sigma_{x,y} [x P(X=x)][y P(Y=y)]\\
                    &= \Sigma_{x} xP(X=x) ~\Sigma_{y} yP(Y=y)\\
                    &= E[X]E[Y]
        \end{align*}
    \end{proof}
\end{enumerate}

\subsection{Properties of Variance}
\begin{enumerate}
    \item $Var[X+\beta] =Var[X]$
    \begin{proof}
        \begin{align*}
            Var[X+\beta] &= E[(X+\beta)^2] - E[(X+\beta)]^2\\
                        &= E[X^2+\beta^2+2X\beta] - (E[x]+\beta)^2\\
                        &= E[X^2] +2\beta E[X] +\beta^2 -E[X]^2-\beta^2-2\beta E[X]\\
                        &= E[X^2]-E[X]^2\\
                        &= Var[X]
        \end{align*}
    \end{proof}
    \item $Var[\alpha X] = \alpha^2 E[X]$
    \begin{proof}
        \begin{align*}
            Var[\alpha X] &= E[(\alpha X)^2] - E[(\alpha X)]^2\\
                        &= E[\alpha^2 X^2] - (\alpha E[x])^2\\
                        &= \alpha^2 E[X^2] -\alpha^2 E[X]^2\\
                        &= \alpha^2(E[X^2]-E[X]^2)\\
                        &= \alpha^2 Var[X]
        \end{align*}
    \end{proof}
    \item $Var[X+Y] = Var[X]+Var[Y] +2 (E[XY]-E[X]E[Y])$
    \begin{proof}
        \begin{align*}
            Var[X+Y] &= E[(X+Y)^2] -E[(X+Y)]^2\\
                     &= E[X^2+Y^2+2XY] -(E[X]+E[Y])^2\\
                     &= E[X^2]+E[Y^2] +2E[XY] -E[X]^2-E[Y]^2-2E[X]E[Y]\\
                     &= (E[X^2]-E[X]^2)+(E[Y^2]-E[Y]^2)+2(E[XY]-E[X]E[Y])\\
                     &= Var(X) +Var(Y) +2(E[XY]-E[X]E[Y])
        \end{align*}
        
        If X and Y are independent, then 
        \[Var[X+Y]= Var[X]+Var[Y]\]
    \end{proof}
    \item  If $\{X_i\}_{i=1}^{n}$ are pairwise independent of each other \\ $Var[X_1 + X_2 + \cdots + X_n] = \sum_i Var[X_i]$ 
\end{enumerate}

\subsection{Properties of Covariance}
\begin{enumerate}
    \item $Cov[X,X] = Var[X]$
    \vspace{-10pt}
    \begin{proof}
        \begin{align*}
            Cov[X,X] &=E[(X-E[X])(X-E[X])]\\
                     &=E[(X-E[X])^2]\\
                     &= Var(X)
        \end{align*}
    Hence, proved.
    \end{proof}
    \item $Cov[X+Z,Y] = Cov[X,Y]+Cov[Z,Y]$
    \vspace{-10pt}
    \begin{proof}
        \begin{align*}
            Cov[X+Z,Y] &= E[(X+Z)Y] -E[(X+Z)]E[Y]\\
                        &= E[XY+ZY] -E[X+Z]E[Y] \\
                        &= E[XY]+E[ZY]-E[X]E[Y]-E[Z]E[Y]\\
                        &= (E[XY]-E[X]E[Y])+E[ZY]-E[Z]E[Y])\\
                        &= Cov[X,Y] +Cov[Z,Y]
        \end{align*}
    \end{proof}
    $Cov[\Sigma_i X_i,Y] = \Sigma_i Cov[X_i, Y]$ is a trivial extension of this property
\end{enumerate}


\end{document}